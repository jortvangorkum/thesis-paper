\section{Cache Management}
\label{sec-cache-manage}

In the optimal case, each intermediate value can be stored. Unfortunately, we are limited by the amount of memory there is available on the machine. Therefore, the amount of cached results needs to be limited. There are two suggestions of limiting the amount of cached results with \textit{Cache Addition Policies} and \textit{Cache Replacement Policies}. Cache addition policies are policies which indicate if an intermediate value can be added to the cache. And the cache replacement policies are policies which remove cached results from the cache based on metrics (e.g., recency, frequency, computational cost, etc.). 

\subsection{Cache Addition Policies}

An example of a cache addition policy would be to determine the recursion depth a data structure has. So, given a node in a tree we then know how many times we have to go into recursion before reaching a leaf. Using that information we can define a filter for the cache, where only elements with a recursion depth of $>i$ can be added to the cache. This filters out a large amount of cached results and could potentially lead to a speed-up, because the lookup in the HashMap could take longer than the calculation itself. 

\pagebreak
The recursion depth can be determined in the same pass as when the hashes are calculated. To accomplish this we introduce an annotated fix-point. The annotated fix-point contains the fix-point as explained in Section \ref*{sec-explicit-recursion} and an annotation for which we store the information about the digest and the recursion depth. The final \inlinehaskell{Merkle} type is the annotated fix-point with the annotation containing the digest and the recursion depth. The implementation of the determining the recursion depth is in Appendix \ref*{app-sec-impl-rec-depth}.

\begin{minted}{haskell}
data AFix f a = AFix { unAFix :: f (AFix f a), getAnnotation :: a }

data MemoInfo = MemoInfo { getDigest :: Digest, getDepth :: Int }

type Merkle f = AFix f MemoInfo
\end{minted}

Then to compute the digest and the recursion depth over a generic datatype, the \inlinehaskell{merkle} function has to be expanded. An additional type constraints \inlinehaskell{HasDepth (PF a)} is added for the new typeclass which computes the recursion depth. Then the digest and depth is computed over the pattern functor and the final annotated fix-point with the digest and recursion depth is returned.

\begin{minted}{haskell}
merkle :: (Regular a, Hashable (PF a), HasDepth (PF a), Functor (PF a)) 
       => a -> Merkle (PF a)
merkle x = AFix py (MemoInfo d h)
  where
    py = merkle <$> from x
    d  = hash py
    h  = depth py

-- Updated cataMerkleState to support cache addition policy for recursion depth
cataMerkleState :: (Functor f, Traversable f) 
                => (f a -> a) -> AFix f MemoInfo 
                -> State (HashMap Digest (a, CacheInfo)) a
cataMerkleState alg (AFix x (MemoInfo di de))
  = do m <- get
      case lookup di m of
        Just a -> return a
        Nothing -> do y <- mapM (cataMerkleState alg) x
                      let r = alg y
                      if minDepth <= de
                        then  modify (insert d r) >> return r
                      else return r   
\end{minted}

However, this does not prevent the memory from filling-up. A more drastic measure is needed to keep the memory from filling up and that is to remove cache results. For this another policy needs to be defined and that are the cache replacement policies.

\subsection{Cache Replacement Policies}

The cache replacement policy can be based on a single metric of a combination of multiple metrics. Unfortunately, we cannot determine the overall best cache replacement policy, because the best cache replacement policy is application specific as stated in \citetitle{acar2003selective}\footnote{``In general the replacement policy must be application-specific, because, for any fixed policy, there are programs whose performance is made worse by that choice.''\cite{acar2003selective}}. As a result, this paper will only describe possible policies which can be used by developers, but not show any results.

Fortunately, it is quite simple to implement the cache replacement policies. At the end of the \inlinehaskell{cataMerkle} computation, a filter is passed over the cache results. If the intermediate value is true with the current cache replacement policy, it gets discarded. Otherwise, the intermediate value stays in the cache. 

\begin{minted}{haskell}
data CacheInfo = CacheInfo { getFrequency :: Int, getRecency :: Int }
  
  -- An example for a replacement policy
replacementPolicy :: CacheInfo -> Bool
replacementPolicy c = getFrequency c <= 1
\end{minted}

\begin{minted}{haskell}
applyPolicy :: HashMap Digest (a, CacheInfo) -> HashMap Digest (a, CacheInfo)
applyPolicy = filter (replacementPolicy . snd)

cataMerkle :: (Functor f, Traversable f) 
           => (f a -> a) -> AFix f MemoInfo -> (a, HashMap Digest (a, CacheInfo))
cataMerkle alg t = (y, applyPolicy ys)
  where
    (y, ys) = runState (cataMerkleState alg t) empty
\end{minted}

There are a multitude of replacement policies which can be chosen to replace cached results. Below, there are some suggestions of what type of replacement policies can be chosen.
\begin{itemize}
  \item Random replacement: remove random elements from the cache.
  \item Recency-based policies: remove elements based on when the element was added.
  \item Frequency-based policies: remove elements based on the amount of lookups.
  \item Computational cost policies: remove elements based on the amount of time it takes to compute the value.
  \item Combination of policies mentioned above. For example, combine the frequency based policy with the computation cost policy.
\end{itemize}