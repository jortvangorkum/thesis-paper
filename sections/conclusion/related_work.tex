\section{Related Work}

There are many other studies which implement incremental computation in functional languages\cite*{hinze2000memo} \cite*{acar2006adaptive} \cite*{firsov2016purely} \cite*{carlsson2002monads}. However, each study has a different approach in implementing incremental computation. The most important part of incremental computation is to know if the input has changed and what has changed. 

\subsection{Comparison of equality in constant time}
To determine the changes between the old and current input is by comparing the inputs for equality. This makes it very important that the comparison of the input for equality can be performed efficiently. The problem with most studies is that for every comparison the entire data structure of the input needs to be traversed through (e.g., a tree), which can become every inefficient when folding over a tree \cite*{hinze2000memo} \cite*{bransen2015incremental}. 

The study \citetitle*{carlsson2002monads}\cite*{carlsson2002monads} performs the equality check in constant time, however the equality check is only on a shallow level. For example, when comparing a list for equality, the two lists are only equal if both lists are empty or both heads are equal, and the tail is the same modifiable. This can lead to recomputing the inputs while they are equal. 

This paper solves these issues, by introducing the use of hash functions. The initial computation for computing the digests is the same as the previous equality, however every incremental computation is in constant time, because the digests are already computed. And it still compares the entire data structure of the input instead of a shallow comparison. Nevertheless, this still has drawbacks, because this solution has the risk of hash collisions, but with a large enough digest size the chance of having a hash collision is very small.

\subsection{Storing the cached results}
Besides, the comparison of equality of the inputs, the results of the given input also has to be stored. The idea of storing the results in a \textit{Trie} is done by multiple studies \cite*{hinze2000memo} \cite*{miraldo2019efficient}. The implementation of the \citetitle{hinze2000memo}\cite*{hinze2000memo} study, MemoTrie\cite*{hackage2022memotrie} uses the input as a key and the results as the value in the trie. This makes the performance of the \texttt{lookup} function dependent on the size of the input, because the performance of the \texttt{lookup} on a trie is dependent on the size of the key. This becomes problematic when the input of a function is a large recursive data structure. 

To solve this issue, the study \citetitle*{miraldo2019efficient} uses the combination of digests and tries. As a result, the \texttt{lookup} function becomes constant time, because the size of the digest is fixed. This study is also the inspiration for using digests and tries.

\subsection{Updating the input}
Also, a difference between this paper and other studies are the updates of the input. This paper uses a Zipper to efficiently update the value in the data structure of the input and then updates the affected nodes. Alternatively, the study \citetitle{carlsson2002monads}\cite{carlsson2002monads} keeps track of all the modifications inside a Monad and then propagates the modifications when the \texttt{propogate} function is called. This is more efficient manner, because if two updates modify the same thing, the first update does not need to be calculated. Additionaly, the data structure does not have to be navigate through, because of the modifiable references. However, for this paper the Zipper was a more easy to use technique, because it made it very easy to update the digests of the parents compared to using a Monad.