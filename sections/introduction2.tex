\chapter{Introduction}


% Instead, use forward references from the narrative in the introduction. The introduction (including the contributions) should survey the whole paper, and therefore forward reference every important part.

Incremental computation is an approach to improve performance by reusing results of a previously computed result when the both inputs are equal. There are multiple applications where incremental computation has a positive effect on: GUIs (e.g., DOM diffing), spreadsheets, attribute grammar evaluation, etc.  An example, where incremental computation has significant effect on performance, would be computing the Fibonacci sequence.

\begin{minted}{haskell}
fib :: Int -> Int
fib 0 = 0
fib 1 = 1
fib n = fib (n - 2) + fib (n - 1)
\end{minted}

The implementation of the incremental computation for the Fibonacci sequence is called \textit{memoization}. Memoization is a term which is associated with a function that caches the result of the function for the given input. A well-used Haskell library which implements memoization is the \texttt{MemoTrie} library\cite*{hackage2022memotrie}.

This works well when the comparison between inputs can be performed in a small amount of time. However, what if the input of that function is a large recursive data structure, for example a tree. Then, to determine if the memoized inputs and the given input are equal the entire tree needs to be traversed through. To improve the comparison of two data structure, we introduce the use of hash functions. Using hash functions to generate \textit{hash values/digests}, the comparison of two data structures can be performed in constant time.

To store the digests, we label every node in the tree with its corresponding digest. The digest represents the internal structure of itself and its children. This new data structure is called a \textit{Hash Tree} or \textit{Merkle Tree}\cite{merkle1987digital}. Using the digests within the data structure, the comparison can easily be performed by just comparing both digests for equality.

However, what if we want to update a small part of the merkle tree? Then the entire merkle tree needs to be rehashed, while only a small part of changes. The digests of the merkle tree only has to change if the node changes or one of the children nodes changes. In other words, only the nodes that changes and all its parents needs to be updated. To efficiently perform this in Haskell we use a technique named \textit{Zipper}\cite{huet1997zipper}.  

The Zipper keeps track, during the navigation from the root node to a specific node, of the path that has been traversed through the data structure. When the specific node is reached, we update the node with a given function and then update the digests accordingly to the new data structure. Therefore, we only have to update a part of the digest in the data structure.

Unfortunately, when we implement this functionality it only works for a single datatype. When we want to support a different datatype the functionality needs to be copied and reimplemented for that specific datatype. This can become quite cumbersome and error-prone for developers. To support a large class of datatypes for this functionality we introduce \textit{Datatype-Generic programming}.

Datatype-generic programming is a technique to exploit the structure of datatypes to define functions by induction over the type structure. To represent datatypes in a generic, we use pattern functors. Then using datatype-generic programming, we define generic functionality for: computing the digests of the data structure, storing the digests inside the data structure, a generic zipper, and, finally functionality for computing the result for a given function and cache with intermediate results. 

However, this does mean that the given function which computes a result needs to use the representation types. The representation types are quite verbose and the extension cannot be a drop-in replacement for existing functionality. To make it easier for developers to use, we introduce \textit{Pattern synonyms}\cite*{pickering2016pattern}. Pattern synonyms add an abstraction over patterns, which can be used to simplify the case expressions used in the given function, making the functionality almost a drop-in extension (we only need to add an underscore to the data constructors). 

Finally, to keep the cache from growing too large for the available amount of memory, we show multiple policies, so that the developer can choose the best policy for their use-case. The policy can be focused on recency, frequency, computational cost or a combination of the previously mentioned metrics.

\section{Contributions}

In summary, the main contributions of the Thesis are the following:

\begin{itemize}
    \item We define an algorithm for incremental computation over recursive data structures. The algorithm uses hashes for comparing if data structures are equal in constant time and a Zipper to efficiently update the recursive data structure without rehashing the entire data structure.
    \item We use datatype-generic programming to write a generic version of the algorithm, to support a large class of datatypes, namely \textit{regular datatypes}.
    \item We use pattern synonyms, to make the developer experience the same as implementing a non-incremental algorithm.
    \item We define cache addition policies and cache replacement policies to optimize the performance/memory usage for different use-cases.
\end{itemize}


% \section{Current Situation}
% \question{Familiar with MemoTrie?}
% \begin{itemize}
%   \item \href{https://hackage.haskell.org/package/MemoTrie}{MemoTrie}
%   \begin{itemize}
%     \item MemoTrie is memoization of a function, compared to this Thesis project which performs memoization on a recursive data structure.
%     \item Does not use hashes to compare the inputs for equality, but uses sums of products to represent the datatypes. This results in keys that fluctuate in size, which can become quite large, while the hashes are of a constant size.
%     \item Has to traverse the complete data structure for equality. This paper the equality check is constant and efficiently updated when data structure changes.
%   \end{itemize}
%   \item \href{https://monospacedmonologues.com/2022/01/memotries/}{Blog MemoTrie}
%   \item \href{https://www.cs.uu.nl/research/techreps/repo/CS-2009/2009-024.pdf}{Pull-Ups, Push-Downs, and Passing It Around.
%   Exercises in Functional Incrementalization}
%   \begin{itemize}
%     \item -
%   \end{itemize}
%   \item \href{https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.3272&rep=rep1&type=pdf}{Memo funtions, polytypially!}
%   \begin{itemize}
%     \item Is the paper version of the MemoTrie implementation
%   \end{itemize}
% \end{itemize}