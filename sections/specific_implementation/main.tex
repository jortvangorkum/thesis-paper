\chapter{Specific Implementation}
\label{chap-spec-impl}

The comparison of two values for equality in Haskell is performed using the \texttt{Eq} typeclass, which implements the equality operator \inlinehaskell{(==) :: a -> a -> Bool}. So, an example implementation of the \texttt{Eq} typeclass for the \texttt{Tree} datatype would be:

\begin{minted}{haskell}
instance Eq a => Eq (Tree a) where
  Leaf x1       == Leaf x2       = x1 == x2
  Node l1 x1 r1 == Node l2 x2 r2 = x1 == x2 && l1 == l2 && r1 == r2
  _             == _             = False
\end{minted}

The problem with using this implementation of the \texttt{Eq} typeclass for memoization is that for every comparison of the \texttt{Tree} datatype the equality is computed. This is inefficient because the equality implementation has to traverse the complete \texttt{Tree} data structure to know if the \texttt{Tree}'s are equal. 

To efficiently compare the \texttt{Tree} datatypes, we need to represent the structure in a manner which does not lead to traversing to the complete \texttt{Tree} data structure. This can be accomplished using a \textit{hash} function. A hash function is a process of transforming a data structure into an arbitrary fixed-size value, where the same input always generates the same output. 

One thing to be cautious when using hashes are \textit{hash collisions}. Hash collisions happen when two different inputs have the same resulting hash. This is because a hash function has a limited amount of bits to represent every possible combination of data. To calculate the chance of a hash collision occurring we use the formula $p = \epsilon^{\frac{-k(k-1)}{2N}}$ from \citetitle{hashcoll2011}\cite{hashcoll2011}. So, given a common hash function CRC-32\cite{peterson1961cyclic}, which has a digest size of 32bits, to get a $50\%$ chance of a hash collision occurring in a collection, it needs $0.5 = \epsilon^{\frac{-k(k-1)}{2\times2^{32}}} \rightarrow k = 77163$ hash values.

\begin{table}[H]
  \centering\begin{tabular}{ | c | c | }
    \hline
    Digest size (in bits) & Collection size \\
    \hline
    32 & 77163 \\
    64 & \num{5.06e9} \\
    128 & \num{2.17e19} \\
    \hline
  \end{tabular}
  \caption{The collection size needed for a $50\%$ chance of getting a hash collision}
  \label{tab-hash-coll}
\end{table}

The hash function ultimately chosen in this paper is the \textit{CityHash}\cite{hackage2022cityhash}. CityHash is a non-cryptographic hash function which works well for hash tables\cite{google2022cityhash}. It supports two different digest sizes: 64- and 128-bit. The digest size used in this paper will be the 64-bit variant. This digest size is chosen, because we think it gives a good balance between performance and the probability of getting a hash collision.

\begin{minted}{haskell}
class Hashable a where
  hash :: a -> Digest

instance Show a => Hashable a where
  hash = cityHash64 . show

instance Hashable a => Hashable (Tree a) where
  hash (Leaf x)     = concatHash [hash "Leaf", hash x]
  hash (Node l x r) = concatHash [hash "Node", hash x, hash l, hash r]
\end{minted}

To keep track of the intermediate results of the computation, we store the results in a \texttt{HashMap}\cite{hackage2022hashmap}. A \texttt{HashMap} is an implementation of mapping a \textit{hashable} key to a value. Internally, the HashMap uses a \textit{Trie} data structure\cite*{fredkin1960trie}. 
\todo[inline]{Add explanation of the Trie. Looking up a value in a trie takes time proportional to the size of the value. Explain HashMap and that it uses Tries, which leads to constant lookups}

% In our next example the \texttt{Digest} is the key and the value is the intermediate result.

\begin{minted}{haskell}
sumTreeInc :: Tree Int -> (Int, HashMap Digest Int)
sumTreeInc l@(Leaf x)     = (x, insert (hash l) x empty)
sumTreeInc n@(Node l x r) = (y, insert (hash n) y (ml <> mr))
  where
    y = x + xl + xr
    (xl, ml) = sumTreeInc l
    (xr, mr) = sumTreeInc r
\end{minted}

Then after the first computation over the entire \texttt{Tree}, we can recompute the \texttt{Tree} using the previously created \texttt{HashMap}. Thus, when we recompute the \texttt{Tree}, we first look in the \texttt{HashMap} if the computation has already been performed then return the result. Otherwise, compute the result and store it in the \texttt{HashMap}.

\begin{minted}{haskell}
sumTreeIncMap :: HashMap Digest Int -> Tree Int -> (Int, HashMap Digest Int)
sumTreeIncMap m l@(Leaf x) = case lookup (hash l) m of
  Just x  -> (x, m) 
  Nothing -> (x, insert (hash l) x empty)
sumTreeIncMap m n@(Node l x r) = case lookup (hash n) m of
  Just x  -> (x, m)
  Nothing -> (y, insert (hash n) y (ml <> mr))
    where
      y = x + xl + xr
      (xl, ml) = sumTreeIncMap m l
      (xr, mr) = sumTreeIncMap m r
\end{minted}

Generating a hash for every computation over the data structure is time-consuming and unnecessary, because most of the \texttt{Tree} data structure stays the same. The work of \citeauthor{miraldo2019efficient}\cite{miraldo2019efficient} inspired the use of the Merkle Tree. A Merkle Tree is a data structure which integrates the hashes within the data structure.

\section{Merkle Tree (\texttt{TreeH})}
First we introduce a new datatype \texttt{TreeH}, which contains a \texttt{Digest} for every constructor in \texttt{Tree}. Then to convert the \texttt{Tree} datatype into the \texttt{TreeH} datatype, the structure of the Tree is hashed and stored into the datatype using the \texttt{merkle} function.

\begin{minted}{haskell}
data TreeH a = LeafH Digest a
             | NodeH Digest (Leaf a) a (Leaf a)
\end{minted}

\begin{minted}{haskell}
merkle :: Tree Int -> TreeH Int
merkle (Leaf x)     = LeafH (hash ["Leaf", show x]) x
merkle (Node l x r) = NodeH d l' x r'
  where
    d = hash ["Node", show x, getDigest l', getDigest r']
    l' = merkle l
    r' = merkle r
\end{minted}

The precomputed hashes can then be used to easily create a \texttt{HashMap}, without computing the hashes every time the \texttt{sumTreeIncH} function is called.

\begin{minted}{haskell}
sumTreeIncH :: TreeH Int -> (Int, HashMap Digest Int)
sumTreeIncH (LeafH h x)     = (x, insert h x empty)
sumTreeIncH (NodeH h l x r) = (y, insert h y (ml <> mr))
  where
    y = x + xl + xr
    (xl, ml) = sumTreeInc l
    (xr, mr) = sumTreeInc r
\end{minted}

The problem with this implementation is, that when the \texttt{Tree} datatype is updated, the entire \texttt{Tree} needs to be converted into a \texttt{TreeH}, which is linear in time. This can be done more efficiently, by only updating the hashes which are impacted by the changes. Which means that only the hashes of the change and the parents need to be updated. 

The first intuition to fixing this would be using a pointer to the value that needs to be changed. But because Haskell is a functional programming language, there are no pointers. Luckily, there is a data structure which can be used to efficiently update the data structure, namely the Zipper\cite{huet1997zipper}.

\input{sections/specific_implementation/zipper.tex}